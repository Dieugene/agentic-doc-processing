# Вопросы к Architect от Tech Lead

## Контекст

Планирую Итерацию 2 (Document Processing Pipeline). Обнаружил архитектурный вопрос, который не освещён в существующих ADR.

---

## Проблема: Хранение результатов обработки документов

**Где обнаружено:**
- Отсутствует в `00_docs/architecture/overview.md`
- Отсутствует в ADR 001-003

**Суть проблемы:**
Не определено, как хранить результаты обработки документов. В текущем plan предполагается FileStorage с JSON, но это не архитектурное решение.

Необходимо определить:
1. Что именно хранить? (DocumentSkeleton, PNG страниц, промежуточные PDF, исходные файлы)
2. В каком формате? (Файлы vs БД)
3. Как инвалидировать при изменениях?
4. Как кэшировать VLM-OCR результаты? (повторная обработка дорогая)

**Влияет на:**
- Задачу 007 (File Storage)
- Производительность системы
- Возможность переобработки
- Восстановление после ошибок

---

## Варианты решений

### Вариант A: Файловое хранилище (JSON)

**Описание:** Все данные в файлах JSON. DocumentSkeleton, NavigationIndex, Taxonomy — как JSON файлы.

**Плюсы:**
- Простота реализации
- Читаемость (отладка)
- Версионирование через git
- Нет внешних зависимостей

**Минусы:**
- Медленная загрузка больших документов
- Негибкие запросы (нужно грузить весь файл)
- Проблемы с конкурентным доступом

**Хранение:**
```
data/
  {document_id}/
    skeleton.json
    navigation_index.json
    taxonomy.json
    snapshots/
      snapshot_{topic_id}.json
```

**Что НЕ хранить:**
- PNG страницы (перерендерить)
- Промежуточные PDF
- Исходные файлы

**Влияние на plan:**
- FileStorage с JSON сериализацией
- Кэширование только в памяти (при запуске)

---

### Вариант B: PostgreSQL (реляционная БД)

**Описание:** Хранение в PostgreSQL с нормализованной схемой.

**Плюсы:**
- Структурированные запросы (SQL)
- Конкурентный доступ
- Транзакционность
- Индексы для быстрого поиска

**Минусы:**
- Миграции схемы
- Сложнее отладка
- Внешняя зависимость

**Схема (упрощённая):**
```sql
documents (id, file_path, hash, created_at)
nodes (id, document_id, type, title, content, parent_id, ...)
navigation_index (document_id, node_id, topic_id, signal)
taxonomy (id, name, parent_id)
snapshots (id, document_id, topic_id, context)
```

**Хранение:**
- DocumentSkeleton → таблицы nodes
- NavigationIndex → таблица navigation_index
- Исходные файлы → BLOB или отдельное файловое хранилище

**Влияние на plan:**
- Additional module: Database layer (SQLAlchemy/asyncpg)
- Миграции схемы (alembic)
- Дополнительная задача: настройка PostgreSQL

---

### Вариант C: MongoDB (документная БД)

**Описание:** Хранение в MongoDB с денормализованными документами.

**Плюсы:**
- Гибкая схема (JSON нативно)
- Быстрая разработка
- Хорошо для иерархических данных

**Минусы:**
- Меньше контроля (нет схемы)
- Проблемы с миграциями
- Размер документов (BSON limit 16MB)

**Структура:**
```javascript
documents:
  {
    _id: "doc_123",
    skeleton: {...},  // весь DocumentSkeleton
    navigation_index: {...},
    taxonomy: {...},
    snapshots: {...}
  }
```

**Влияние на plan:**
- Additional module: MongoDB layer (motor/asyncpg)
- Additional task: настройка MongoDB

---

### Вариант D: Гибрид (файлы + метаданные в БД)

**Описание:** Большие данные в файлах, метаданные и связи в БД.

**Плюсы:**
- Лучшее из двух миров
- Быстрые запросы через метаданные
- Большие данные не грузят БД

**Минусы:**
- Сложность (два хранилища)
- Синхронизация файлов и БД

**Структура:**
```sql
-- БД
documents (id, file_path, skeleton_path, index_path, created_at)

-- Файлы
data/{document_id}/
  skeleton.json
  navigation_index.json
```

**Влияние на plan:**
- БД для метаданных
- FileStorage для больших данных
- Additional задачи: синхронизация

---

## Дополнительные вопросы

### Кэширование VLM-OCR результатов

VLM-OCR обработка дорогая. Как кэшировать?

**Вариант A:** Не кэшировать, всегда обрабатывать заново
- Плюсы: Просто
- Минусы: Долго, дорого

**Вариант B:** Кэшировать PNG страницы
- Плюсы: Не нужно рендерить заново
- Минусы: Место на диске

**Вариант C:** Кэшировать VLM-OCR результаты (DocumentData)
- Плюсы: Не вызывать VLM заново
- Минусы: Кэш инвалидировать сложно

### Инвалидация

При изменении исходного файла:
- Что делать с существующим DocumentSkeleton?
- Как обнаружить изменение? (hash, timestamp, размер)
- Какие снэпшоты инвалидировать? (все или зависимые)

---

## Рекомендация

**Вариант A (файловое хранилище)** для v1.0

**Обоснование:**
- Простота — критично для быстрого старта
- Документы большие, но не тысячи
- Отсутствие конкурентной записи (один пользователь обрабатывает)
- Версионирование через git полезно для отладки

**Для будущих версий:**
- Если появится многопользовательность → B или C
- Если documentos станут тысячи → B или C

**По кэшированию:**
- Не кэшировать PNG (переобработка редкая)
- Не кэшировать VLM-OCR результаты (сложно инвалидировать)
- Оптимизировать через batch prompts (ADR-003)

---

## Вопрос к Architect

1. **Какой подход к хранению выбрать для v1.0?**
   - Файловое хранилище (JSON)?
   - Сразу PostgreSQL/MongoDB?
   - Или другой вариант?

2. **Что именно хранить?**
   - Только результаты (skeleton, index)?
   - Или PNG страницы и промежуточные PDF тоже?

3. **Как инвалидировать при изменении исходного файла?**
   - Переписывать всё?
   - Или версионировать?
